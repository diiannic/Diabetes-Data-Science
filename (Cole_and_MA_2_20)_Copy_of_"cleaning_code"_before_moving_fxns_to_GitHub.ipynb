{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Cole and MA 2/20) Copy of \"cleaning code\" before moving fxns to GitHub",
      "provenance": [],
      "collapsed_sections": [
        "FhHHTaq7_jpl",
        "kws4Grz2TOlg",
        "yEphSY6ymtdh",
        "yutGqrikm2Gw"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diiannic/Diabetes-Data-Science/blob/master/(Cole_and_MA_2_20)_Copy_of_%22cleaning_code%22_before_moving_fxns_to_GitHub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MFjCJfu_no-",
        "colab_type": "text"
      },
      "source": [
        "# ReadMe\n",
        "\n",
        "Put New (in order) glucose bin creation function in and will continue cleaning/checking the code\n",
        "\n",
        "Add filling in of the previous/next bin to  elif statement in CreateGlucoseBins() (labeled with a comment)\n",
        "\n",
        "Made edited the document to get rid of ALL timezone changes\n",
        "\n",
        "Looking to use a Person object to store data instead of all the nested lists\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggys1sRgbEt",
        "colab_type": "text"
      },
      "source": [
        "# Installation and Importation\n",
        "\n",
        "Each of the pip installations may take a minute or two.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRgAAFjpcUMx",
        "colab_type": "code",
        "outputId": "48da5cd4-8020-479b-e4ff-f267a5f52cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "pip install scipy==1.2 --upgrade"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scipy==1.2 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAnbvOfecV6x",
        "colab_type": "code",
        "outputId": "98e3a081-4451-48b1-be6b-cd5ab2199c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "pip install -U statsmodels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: statsmodels in /usr/local/lib/python3.6/dist-packages (0.11.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->statsmodels) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ctC3b3F73i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Cell\n",
        "import pylab,numpy \n",
        "from dateutil.parser import * #formats date strings into datetimes\n",
        "from datetime import * # this allows for use of datetime objects\n",
        "import math\n",
        "import os # importing files\n",
        "import sys # importing files\n",
        "import importlib # importing libraries\n",
        "from importlib import util\n",
        "import numpy as np                               # vectors and matrices\n",
        "import pandas as pd                              # tables and data manipulations\n",
        "import matplotlib.pyplot as plt                  # plots\n",
        "import seaborn as sns                            # more plots\n",
        "from dateutil.relativedelta import relativedelta # working with dates with style\n",
        "from scipy.optimize import minimize              # for function minimization\n",
        "import statistics #Median usage\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import pytz  \n",
        "from sklearn.cluster import KMeans               # kmeans clustering\n",
        "from sklearn import metrics                      # kmeans clustering\n",
        "from scipy.spatial.distance import cdist         # kmeans clustering\n",
        "import warnings\n",
        "import itertools\n",
        "import statsmodels.api as sm \n",
        "import pandas as pd\n",
        "import scipy.cluster.hierarchy as hac\n",
        "from scipy.spatial.distance import pdist\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from scipy.cluster.hierarchy import cophenet\n",
        "from scipy.cluster.hierarchy import fcluster"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyzKJSQo_zjm",
        "colab_type": "text"
      },
      "source": [
        "#Load Google Drive\n",
        "\n",
        "Once this cell is run, it will ask for an authorization code, thus checking that you are authorized to access/use the data. Follow the link, and enter your authorization code.\n",
        "\n",
        "This step may take one or two minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLpu5oTm4lRs",
        "colab_type": "code",
        "outputId": "27e7a99b-e40f-47ea-a9a5-92a0202b72df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQMXfNOMpAM-",
        "colab_type": "text"
      },
      "source": [
        "# Load Functions from Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My-nlBvQo_Jt",
        "colab_type": "code",
        "outputId": "f8e3a33f-312e-4853-ba78-9bb26ecd8df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/diiannic/Diabetes-Data-Science.git\n",
        "\n",
        "!cp Diabetes-Data-Science/Data_Science_Functions.py .\n",
        "\n",
        "from Data_Science_Functions import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Diabetes-Data-Science'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 25 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (25/25), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f2Xx3EPImXR",
        "colab_type": "text"
      },
      "source": [
        "# Download Data to Colab\n",
        "\n",
        "Run the following cells in this section, Creating Bin Functionsup until Main(); they should take almost no time at all to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Smqp0XSnaMT",
        "colab_type": "code",
        "outputId": "24f7e9df-65f5-43cb-bd52-d4dcb67c115d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "def ImportFileNames(csvName):\n",
        "\n",
        "  df = pd.read_csv(csvName)\n",
        "  \"\"\"\n",
        "  Creates the original three lists of data from the selected CSV file.  \n",
        "  cgm: continuous blood glucose mmol/liter\n",
        "  bas: basal in units/hour\n",
        "  bol: bolus in units\n",
        "  \"\"\"\n",
        "\n",
        "  old = df.old\n",
        "  old = old[0:6]\n",
        "  new = df.new\n",
        "  \n",
        "  return old, new"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0f44375ba237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImportFileNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'csvName' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKawtS3UfYYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load tidals package locally if it does not exist globally\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "description: example script of how to load the tidals package\n",
        "created: 2018-02-21\n",
        "author: Ed Nykaza\n",
        "license: BSD-2-Clause\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Loads desired person's diabetes CSV file, and makes it accessible for data \n",
        "extraction, assuming that we have loaded in the CSVs to the google drive.\n",
        "\n",
        "Also returns the correct size of the bins based on the cbg, basal, and bolus.\n",
        "\"\"\"\n",
        "\n",
        "def ImportData(csvName, dataType): # Good to go\n",
        "\n",
        "  df = pd.read_csv(csvName, low_memory=False)\n",
        "  \"\"\"\n",
        "  Creates the original three lists of data from the selected CSV file.  \n",
        "  cgm: continuous blood glucose mmol/liter\n",
        "  bas: basal in units/hour\n",
        "  bol: bolus in units\n",
        "  \"\"\"\n",
        "\n",
        "  cgm = df.loc[df.type == \"cbg\", [\"time\", \"value\"]]\n",
        "  bas = df.loc[df.type == \"basal\", [\"time\", \"rate\", \"duration\"]]\n",
        "  bol = df.loc[df.type == \"bolus\", [\"time\", \"normal\"]]\n",
        "      \n",
        "  #Checking for what the greatest start and end bounds between glucose, basal, and bolus\n",
        "  \n",
        "  #glucose\n",
        "  if (dataType == \"new\"):\n",
        "    startGlucoseTime = cgm[\"time\"][int(cgm.index[0])]\n",
        "    endGlucoseTime = cgm[\"time\"][int(cgm.index[-1])]\n",
        "  else:\n",
        "    endGlucoseTime = cgm[\"time\"][int(cgm.index[0])]\n",
        "    startGlucoseTime = cgm[\"time\"][int(cgm.index[-1])]\n",
        "    \n",
        "  startGlucoseTime = parse(startGlucoseTime) # parses time strings into datetime values\n",
        "  startGlucoseTime = startGlucoseTime.replace(microsecond = 0, tzinfo=pytz.UTC)  \n",
        "  startGlucoseTime = startGlucoseTime.replace(tzinfo=None)\n",
        "  \n",
        "  endGlucoseTime = parse(endGlucoseTime) # parses time strings into datetime values\n",
        "  endGlucoseTime = endGlucoseTime.replace(microsecond = 0, tzinfo=pytz.UTC)  \n",
        "  endGlucoseTime = endGlucoseTime.replace(tzinfo=None)\n",
        "\n",
        "  #basal\n",
        "  if (dataType == \"new\"):\n",
        "    startBasalTime = bas[\"time\"][int(bas.index[0])]\n",
        "    endBasalTime = bas[\"time\"][int(bas.index[-1])]\n",
        "  else:\n",
        "    endBasalTime = bas[\"time\"][int(bas.index[0])]\n",
        "    startBasalTime = bas[\"time\"][int(bas.index[-1])]\n",
        "\n",
        "  startBasalTime = parse(startBasalTime) # parses time strings into datetime values\n",
        "  startBasalTime = startBasalTime.replace(microsecond = 0, tzinfo=pytz.UTC)  \n",
        "  startBasalTime = startBasalTime.replace(tzinfo=None) \n",
        "  \n",
        "  endBasalTime = parse(endBasalTime) # parses time strings into datetime values\n",
        "  endBasalTime = endBasalTime.replace(microsecond = 0, tzinfo=pytz.UTC)  \n",
        "  endBasalTime = endBasalTime.replace(tzinfo=None) \n",
        "  \n",
        "  #bolus\n",
        "  if (dataType == \"new\"):\n",
        "    startBolusTime = bol[\"time\"][int(bol.index[0])]\n",
        "    endBolusTime = bol[\"time\"][int(bol.index[-1])]\n",
        "  else:\n",
        "    endBolusTime = bol[\"time\"][int(bol.index[0])]\n",
        "    startBolusTime = bol[\"time\"][int(bol.index[-1])]\n",
        "\n",
        "  startBolusTime = parse(startBolusTime) # parses time strings into datetime values\n",
        "  startBolusTime = startBolusTime.replace(microsecond = 0, tzinfo=pytz.UTC)  \n",
        "  startBolusTime = startBolusTime.replace(tzinfo=None) \n",
        "  \n",
        "  endBolusTime = parse(endBolusTime) # parses time strings into datetime values\n",
        "  endBolusTime = endBolusTime.replace(microsecond = 0, tzinfo=pytz.UTC)  \n",
        "  endBolusTime = endBolusTime.replace(tzinfo=None)\n",
        "  \n",
        "  if (startGlucoseTime < startBasalTime):\n",
        "    if (startGlucoseTime < startBolusTime):\n",
        "      startBinDatetime = startGlucoseTime\n",
        "    else:\n",
        "      startBinDatetime = startBolusTime\n",
        "  else:\n",
        "    if (startBasalTime < startBolusTime):\n",
        "      startBinDatetime = startBasalTime\n",
        "    else:\n",
        "      startBinDatetime = startBolusTime\n",
        "      \n",
        "  if (endGlucoseTime > endBasalTime):\n",
        "    if (endGlucoseTime > endBolusTime):\n",
        "      endBinDatetime = endGlucoseTime\n",
        "    else:\n",
        "      endBinDatetime = endBolusTime\n",
        "  else:\n",
        "    if (endBasalTime > endBolusTime):\n",
        "      endBinDatetime = endBasalTime\n",
        "    else:\n",
        "      endBinDatetime = endBolusTime\n",
        "  \n",
        "  #standardizes start and end dates to midnight with buffer\n",
        "  startBinDatetime = datetime(startBinDatetime.year, startBinDatetime.month, startBinDatetime.day, 0, 0)\n",
        "  endBinDatetime = datetime(endBinDatetime.year, endBinDatetime.month, endBinDatetime.day, 0, 0) + timedelta(days = 1)\n",
        "  return cgm, bas, bol, startBinDatetime, endBinDatetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS6StbVOIo_a",
        "colab_type": "text"
      },
      "source": [
        "# Creating Bin Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy7E1h_MIK6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This function puts the glucose data into a usable form for modeling and analysis.\n",
        "We break the dates from the start of recorded data, to the end, into 5 minute \n",
        "intervals, and fill in each 'bin' with its associated blood glucose value.\n",
        "We perform a weighted average by calculating the midpoint between the current \n",
        "time and its two neighbors and, assuming that the gap between said neighbors \n",
        "is less than 10 minutes, we add in the glucose value to the designated bins.\n",
        "If a bin is not entirely full, then it is considered an empty bin.\n",
        "\n",
        "@newData: type of data (as in the old data)\n",
        "@tz: the time zone the person to whom these glucose bin belongs lives in\n",
        "\"\"\"\n",
        "  \n",
        "def CreateGlucoseBins(cgm, newData, startBinDatetime, endBinDatetime):\n",
        "  \"\"\"\n",
        "  Puts the data into a 2 dimensional list: totalBolusDayList; it contains:\n",
        "    - a list of times in a special python form.\n",
        "    - a list of glucose levels\n",
        "  The index of the times and glucose levels match up such that each time is \n",
        "  associated with a particular glucose value.\n",
        "  \"\"\"\n",
        "  totalGlucoseDayList = [[], []]\n",
        "  for i in range(len(cgm[\"time\"])):\n",
        "    totalGlucoseDayList[0].append(cgm[\"time\"][int(cgm.index[i])]) \n",
        "    totalGlucoseDayList[1].append(float(cgm[\"value\"][int(cgm.index[i])]) * 18)\n",
        "    \n",
        "  if (newData == \"old\"):  \n",
        "    totalGlucoseDayList[0].reverse()\n",
        "    totalGlucoseDayList[1].reverse()  \n",
        "    \n",
        "  \"\"\"\n",
        "  Within the TIME list, we put the times into a more usable form, from the \n",
        "  weird python formatting, to a dateTime object that looks like:\n",
        "\n",
        "  (year, month, day, hour, minute, second)\n",
        "\n",
        "  This also cuts off the microseconds and time zone information\n",
        "  \"\"\"\n",
        "\n",
        "  for i in range(len(totalGlucoseDayList[0])):\n",
        "    totalGlucoseDayList[0][i] = parse(totalGlucoseDayList[0][i]) # parses time strings into datetime values\n",
        "    totalGlucoseDayList[0][i] = totalGlucoseDayList[0][i].replace(microsecond = 0, tzinfo=pytz.UTC)  \n",
        "    totalGlucoseDayList[0][i] = totalGlucoseDayList[0][i].replace(tzinfo=None) \n",
        "\n",
        "  \n",
        "  countDatetime = startBinDatetime\n",
        "  datetimeBin = []\n",
        "  glucoseBinList = []\n",
        "\n",
        "  while (countDatetime != endBinDatetime): # while the count time is not 5 mins past the last day in the sequence\n",
        "    weekno = countDatetime.weekday()\n",
        "    if weekno<5:\n",
        "      day = \"Weekday\"\n",
        "    else:\n",
        "      day = \"Weekend\"\n",
        "    datetimeBin = [countDatetime, None, datetime(1, 1, 1, 0, 0), day] # time at bin (lower bound), BG value of bin, portion of bin which has been filled\n",
        "    glucoseBinList.append(datetimeBin)\n",
        "    countDatetime = countDatetime + timedelta(minutes=5)\n",
        "    \n",
        "\n",
        "  for i in range(len(totalGlucoseDayList[0])):\n",
        "\n",
        "    #number of seconds between now and starting date\n",
        "    curDateSeconds = ((totalGlucoseDayList[0][i] - startBinDatetime).days * 24 * 60 * 60) + ((totalGlucoseDayList[0][i] - startBinDatetime).seconds)\n",
        "    #timedelta only has capability to return in terms of days and seconds\n",
        "    if (i == 0): #totalGlucoseDayList is in reverse chronological order, so prevDateDif is at end\n",
        "      prevDateDif = 100000000 #make unreasonably large so it doesn't affect data\n",
        "    else:\n",
        "      prevDateSeconds = ((totalGlucoseDayList[0][i-1] - startBinDatetime).days * 24 * 60 * 60) + ((totalGlucoseDayList[0][i-1] - startBinDatetime).seconds)\n",
        "      prevDateDif = curDateSeconds - prevDateSeconds\n",
        "    if (i == len(totalGlucoseDayList[0]) - 1):\n",
        "      nextDateDif = 100000000\n",
        "    else:\n",
        "      nextDateSeconds = ((totalGlucoseDayList[0][i+1] - startBinDatetime).days * 24 * 60 *60) + ((totalGlucoseDayList[0][i+1] - startBinDatetime).seconds)\n",
        "      nextDateDif = nextDateSeconds - curDateSeconds\n",
        "    #declare binIndex to be the bin that the current date is based in\n",
        "    binIndex = int((curDateSeconds / 60) // 5) # / 60 is to convert from seconds to minutes; // 5 is to convert to 5 minute intervals\n",
        "    \n",
        "\n",
        "    if (prevDateDif <= 600): #General case (prevDate is less than 10 min away - midpoint is witin 5 min); find midpoint\n",
        "      #declare midpoint\n",
        "      midpoint = startBinDatetime + timedelta(seconds = prevDateSeconds + (prevDateDif/2)) #convert to datetime object for arithmetic\n",
        "      \n",
        "      if (midpoint >= glucoseBinList[binIndex][0]):\n",
        "        #adds the weighted glucose value to the current bin in between the current time and the midpoint.\n",
        "        midDateDif = (totalGlucoseDayList[0][i] - midpoint).seconds\n",
        "        glucoseBinList[binIndex][2] = glucoseBinList[binIndex][2] + timedelta(seconds=midDateDif) \n",
        "        if (glucoseBinList[binIndex][1] == None):\n",
        "          glucoseBinList[binIndex][1] = 0\n",
        "        glucoseBinList[binIndex][1] += (midDateDif / 300) * totalGlucoseDayList[1][i]\n",
        "\n",
        "      elif (midpoint < glucoseBinList[binIndex][0]):\n",
        "        #This part adds the weighted glucose value to the current bin in between the current time and the lower edge of the bin\n",
        "        prevBinDateDif = (totalGlucoseDayList[0][i] - glucoseBinList[binIndex][0]).seconds\n",
        "        glucoseBinList[binIndex][2] = glucoseBinList[binIndex][2] + timedelta(seconds=prevBinDateDif) \n",
        "        if (glucoseBinList[binIndex][1] == None):\n",
        "          glucoseBinList[binIndex][1] = 0\n",
        "        glucoseBinList[binIndex][1] += (prevBinDateDif / 300) * totalGlucoseDayList[1][i]\n",
        "        #This next part adds the weighted glucose value to the previous bin in between the upper edge of the previous bin and the midpoint\n",
        "        midDateDif = (glucoseBinList[binIndex][0] - midpoint).seconds\n",
        "        glucoseBinList[binIndex - 1][2] = glucoseBinList[binIndex - 1][2] + timedelta(seconds=midDateDif) \n",
        "        if (glucoseBinList[binIndex - 1][1] == None):\n",
        "          glucoseBinList[binIndex - 1][1] = 0\n",
        "        glucoseBinList[binIndex - 1][1] += (midDateDif / 300) * totalGlucoseDayList[1][i]\n",
        "\n",
        "      '''\n",
        "      Added filling in of the previous bin to  elif statement below:\n",
        "      '''    \n",
        "    elif (prevDateDif > 600): #PrevDate more than 10 min away\n",
        "      #prevBinDateDif is the difference in time in seconds between the curDate's time, and the low bound on the bin's times\n",
        "      prevBinDateDif = (totalGlucoseDayList[0][i] - glucoseBinList[binIndex][0]).seconds\n",
        "      glucoseBinList[binIndex][2] = glucoseBinList[binIndex][2] + timedelta(seconds=prevBinDateDif) \n",
        "      if (glucoseBinList[binIndex][1] == None):\n",
        "        glucoseBinList[binIndex][1] = 0\n",
        "      glucoseBinList[binIndex][1] += (prevBinDateDif / 300) * totalGlucoseDayList[1][i]\n",
        "      #This next part adds the weighted glucose value to the previous bin in between the upper edge of the previous bin and the midpoint\n",
        "      timeInPrevBin = 300 - prevBinDateDif\n",
        "      glucoseBinList[binIndex - 1][2] = glucoseBinList[binIndex - 1][2] + timedelta(seconds=timeInPrevBin) \n",
        "      if (glucoseBinList[binIndex - 1][1] == None):\n",
        "        glucoseBinList[binIndex - 1][1] = 0\n",
        "      glucoseBinList[binIndex - 1][1] += (timeInPrevBin / 300) * totalGlucoseDayList[1][i] \n",
        "    \n",
        "    if (nextDateDif <= 600): #General case; find midpoint\n",
        "      #declare midpoint\n",
        "      midpoint = startBinDatetime + timedelta(seconds = curDateSeconds + (nextDateDif/2)) #convert to datetime object for arithmetic\n",
        "      \n",
        "      if (midpoint < glucoseBinList[binIndex + 1][0]):\n",
        "        #adds the weighted glucose value to the current bin in between the current time and the midpoint.\n",
        "        midDateDif = (midpoint - totalGlucoseDayList[0][i]).seconds\n",
        "        glucoseBinList[binIndex][2] = glucoseBinList[binIndex][2] + timedelta(seconds=midDateDif) \n",
        "        if (glucoseBinList[binIndex][1] == None):\n",
        "          glucoseBinList[binIndex][1] = 0\n",
        "        glucoseBinList[binIndex][1] += (midDateDif / 300) * totalGlucoseDayList[1][i]\n",
        "\n",
        "      elif (midpoint >= glucoseBinList[binIndex + 1][0]):\n",
        "        #This part adds the weighted glucose value to the current bin in between the current time and the upper edge of the bin\n",
        "        nextBinDateDif = (glucoseBinList[binIndex + 1][0] - totalGlucoseDayList[0][i]).seconds\n",
        "        glucoseBinList[binIndex][2] = glucoseBinList[binIndex][2] + timedelta(seconds=nextBinDateDif)  \n",
        "        if (glucoseBinList[binIndex][1] == None):\n",
        "          glucoseBinList[binIndex][1] = 0\n",
        "        glucoseBinList[binIndex][1] += (nextBinDateDif / 300) * totalGlucoseDayList[1][i]\n",
        "        #This next part adds the weighted glucose value to the previous bin in between the lower edge of the next bin and the midpoint\n",
        "        midDateDif = (midpoint - glucoseBinList[binIndex + 1][0]).seconds    \n",
        "        glucoseBinList[binIndex + 1][2] = glucoseBinList[binIndex + 1][2] + timedelta(seconds=midDateDif)  \n",
        "        if (glucoseBinList[binIndex + 1][1] == None):\n",
        "          glucoseBinList[binIndex + 1][1] = 0\n",
        "        glucoseBinList[binIndex + 1][1] += (midDateDif / 300) * totalGlucoseDayList[1][i]\n",
        "    \n",
        "    \n",
        "      '''\n",
        "      Add filling in of the next bin to  elif statement below:\n",
        "      '''  \n",
        "    elif (nextDateDif > 600): #NextDate is more than 10 min away\n",
        "      #nextBinDateDif is the difference in time in seconds between the curDate's time, and the high bound on the bin's times\n",
        "      nextBinDateDif = (glucoseBinList[binIndex + 1][0] - totalGlucoseDayList[0][i]).seconds\n",
        "      glucoseBinList[binIndex][2] = glucoseBinList[binIndex][2] + timedelta(seconds=nextBinDateDif) #update the portion of bin that is filled\n",
        "      if (glucoseBinList[binIndex][1] == None): #confirm there is a glucose value for this time interval\n",
        "        glucoseBinList[binIndex][1] = 0\n",
        "      glucoseBinList[binIndex][1] += (nextBinDateDif / 300) * totalGlucoseDayList[1][i] #update glucose value\n",
        "      #This next part adds the weighted glucose value to the previous bin in between the lower edge of the next bin and the midpoint\n",
        "      timeInNextBin = 300 - nextBinDateDif\n",
        "      glucoseBinList[binIndex + 1][2] = glucoseBinList[binIndex + 1][2] + timedelta(seconds=timeInNextBin)  \n",
        "      if (glucoseBinList[binIndex + 1][1] == None):\n",
        "        glucoseBinList[binIndex + 1][1] = 0\n",
        "      glucoseBinList[binIndex + 1][1] += (timeInNextBin / 300) * totalGlucoseDayList[1][i] \n",
        "      \n",
        "  '''\n",
        "  This section of code takes the glucoseBinList and shaves off any bins that are either \n",
        "  too big (because of some bug) or too small (not enough values).  Thus, we are left\n",
        "  with only full bins, or None to represent an unfull bin.  \n",
        "  '''\n",
        "\n",
        "  '''\n",
        "  Change the for loop below if you want to include \"unfull\" bins.\n",
        "  Ex. Take the average of the surrounding bins to create a \"predicted\" BG value for that bin rather than setting it to 0\n",
        "  '''\n",
        "\n",
        "  for i in range(len(glucoseBinList)):\n",
        "    if (glucoseBinList[i][2] < datetime(1, 1, 1, 0, 4, 55)):\n",
        "      glucoseBinList[i][1] = None\n",
        "      glucoseBinList[i][2] = datetime(1, 1, 1, 0, 0)\n",
        "\n",
        "  return glucoseBinList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFtNImwCEYt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This is the new and updated CreateBasalBins().  While the above function \n",
        "simply looks at the start time of the currrent basal amount and the end time of \n",
        "the next, this function takes the duration and applies the rate over said \n",
        "duration.  \n",
        "\n",
        "totalBasalYearList: A 2-D list containing, for each entry, 3 values: the time it\n",
        "begins, the rate in units per hour at which the insulin is added, and the \n",
        "duration the insulin lasts.\n",
        "\n",
        "timeSlice: The amount of time from the start of the bins to the current basal\n",
        "entry.\n",
        "\n",
        "timeIndex: The time of the current bin that the basal entry should reside in.\n",
        "\n",
        "timeSliceInBin: The amount of time of the current bin occupied by the current \n",
        "basal entry.\n",
        "\"\"\"\n",
        "\n",
        "def CreateBasalBins(bas, newData, start, end):\n",
        "  totalBasalYearList = [[], [], []]\n",
        "  for i in range(len(bas[\"time\"])):\n",
        "    totalBasalYearList[0].append(bas[\"time\"][int(bas.index[i])])\n",
        "    totalBasalYearList[1].append(bas[\"rate\"][int(bas.index[i])])\n",
        "    try:  \n",
        "      totalBasalYearList[2].append(int(int(bas[\"duration\"][int(bas.index[i])]) / 1000))\n",
        "    except:\n",
        "      totalBasalYearList[2].append(0)\n",
        "\n",
        "  for i in range(len(totalBasalYearList[0])):\n",
        "    totalBasalYearList[0][i] = parse(totalBasalYearList[0][i]) # parses time strings into datetime values\n",
        "    totalBasalYearList[0][i] = totalBasalYearList[0][i].replace(microsecond = 0, tzinfo=pytz.UTC)  \n",
        "    totalBasalYearList[0][i] = totalBasalYearList[0][i].replace(tzinfo=None) \n",
        "    \n",
        "  for i in range(len(totalBasalYearList[1])):\n",
        "    if (math.isnan(totalBasalYearList[1][i])):\n",
        "      totalBasalYearList[1][i] = 0\n",
        "\n",
        "  if (newData == \"old\"):\n",
        "    totalBasalYearList[0].reverse()\n",
        "    totalBasalYearList[1].reverse()\n",
        "    totalBasalYearList[2].reverse()\n",
        "\n",
        "  startBinDatetime = start\n",
        "  endBinDatetime = end\n",
        "\n",
        "  countDatetime = startBinDatetime\n",
        "  datetimeBin = []\n",
        "  basalBinList = []\n",
        "\n",
        "  while (countDatetime != endBinDatetime): # while the count time is not 5 mins past the last day in the sequence\n",
        "    weekno = countDatetime.weekday()\n",
        "    if weekno < 5:\n",
        "      day = \"Weekday\"\n",
        "    else:\n",
        "      day = \"Weekend\"\n",
        "    datetimeBin = [countDatetime, 0, day] # time at bin (lower bound), BG value of bin, portion of bin which has been filled\n",
        "    basalBinList.append(datetimeBin)\n",
        "    countDatetime = countDatetime + timedelta(minutes=5) \n",
        "\n",
        "  for i in range(len(totalBasalYearList[0])):\n",
        "    timeSlice = totalBasalYearList[0][i] - startBinDatetime  \n",
        "    timeIndex = int(((timeSlice.days * 24 * 60 * 60) + timeSlice.seconds) / 300)\n",
        "    while (totalBasalYearList[2][i] > 0):\n",
        "      if (timeIndex + 1 < len(basalBinList) and (totalBasalYearList[0][i] + timedelta(seconds=totalBasalYearList[2][i])) > basalBinList[timeIndex + 1][0]):\n",
        "        timeSliceInBin = (basalBinList[timeIndex + 1][0] - totalBasalYearList[0][i])\n",
        "        binProportion = ((timeSliceInBin.days * 24 * 60 * 60) + timeSliceInBin.seconds) / 300\n",
        "        basalBinList[timeIndex][1] += binProportion * totalBasalYearList[1][i]/12\n",
        "        totalBasalYearList[0][i] = totalBasalYearList[0][i] + timedelta(seconds = (timeSliceInBin.days * 24 * 60 * 60) + timeSliceInBin.seconds)\n",
        "        totalBasalYearList[2][i] = totalBasalYearList[2][i] - ((timeSliceInBin.days * 24 * 60 * 60) + timeSliceInBin.seconds) \n",
        "        timeIndex += 1\n",
        "      else:\n",
        "        binProportion = totalBasalYearList[2][i] / 300\n",
        "        basalBinList[timeIndex][1] += binProportion * totalBasalYearList[1][i]/12\n",
        "        totalBasalYearList[0][i] = totalBasalYearList[0][i] + timedelta(seconds = totalBasalYearList[2][i])\n",
        "        totalBasalYearList[2][i] = totalBasalYearList[2][i] - totalBasalYearList[2][i]  \n",
        "      \n",
        "  return basalBinList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEQ5N7IuIIdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This function creates the bins containing the bolus values.  Because bolus is a \n",
        "single infusion of insulin, however, we put the total \"normal\" amount into the \n",
        "bin that bounds the time of infusion.\n",
        "\"\"\"\n",
        "  \n",
        "def CreateBolusBins(bol, newData, start, end):\n",
        "  totalBolusYearList = [[], []]\n",
        "  for i in range(len(bol[\"time\"])):\n",
        "    totalBolusYearList[0].append(bol[\"time\"][int(bol.index[i])])\n",
        "    totalBolusYearList[1].append(bol[\"normal\"][int(bol.index[i])])\n",
        "\n",
        "  for i in range(len(totalBolusYearList[0])):\n",
        "    totalBolusYearList[0][i] = parse(totalBolusYearList[0][i]) # parses time strings into datetime values\n",
        "    totalBolusYearList[0][i] = totalBolusYearList[0][i].replace(microsecond = 0, tzinfo=pytz.UTC)  \n",
        "    totalBolusYearList[0][i] = totalBolusYearList[0][i].replace(tzinfo=None) \n",
        "  \n",
        "  if (newData != \"new\"):\n",
        "    totalBolusYearList[0].reverse()\n",
        "    totalBolusYearList[1].reverse()  \n",
        "\n",
        "  startBinDatetime = start  \n",
        "  endBinDatetime = end\n",
        "\n",
        "  countDatetime = startBinDatetime\n",
        "  datetimeBin = []\n",
        "  bolusBinList = []\n",
        "\n",
        "  while (countDatetime != endBinDatetime): # while the count time is not 5 mins past the last day in the sequence\n",
        "    weekno = countDatetime.weekday()\n",
        "    if weekno < 5:\n",
        "      day = \"Weekday\"\n",
        "    else:\n",
        "      day = \"Weekend\"\n",
        "    datetimeBin = [countDatetime, 0, day] # time at bin (lower bound), BG value of bin, portion of bin which has been filled\n",
        "    bolusBinList.append(datetimeBin)\n",
        "    countDatetime = countDatetime + timedelta(minutes=5) \n",
        "\n",
        "  for i in range(len(totalBolusYearList[0])):\n",
        "    timeSlice = totalBolusYearList[0][i] - startBinDatetime  \n",
        "    timeIndex = int(((timeSlice.days * 24 * 60 * 60) + timeSlice.seconds) / 300) \n",
        "    bolusBinList[timeIndex][1] += totalBolusYearList[1][i]\n",
        "\n",
        "          \n",
        "  return bolusBinList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifog7wNFXx0a",
        "colab_type": "text"
      },
      "source": [
        "# Formatting Bins\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJQTxRxpQfNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "binList: a gigantic (1 dimensional) list containing all the blood \n",
        "glucose values in their five minute bins.\n",
        "\"\"\"\n",
        "\n",
        "def ExpandBins(timeValueBinList):\n",
        "\n",
        "  binList = []\n",
        "  \n",
        "  for i in range(len(timeValueBinList)):\n",
        "    binList.append(timeValueBinList[i][1])\n",
        "  \n",
        "  return binList\n",
        "  \n",
        "\"\"\"\n",
        "Takes the values from their original bin format and puts them into a 1-dimesional\n",
        "list.  Then, put each day's worth of bin-values into its own list, and add it to\n",
        "dayList.  monthList is similar, but just separates the bin-values by month.\n",
        "\n",
        "binList: a gigantic (1 dimensional) list containing all the blood \n",
        "glucose values in their five minute bins.\n",
        "\n",
        "subSetSize: size of the internal lists in terms of hours (so 24 would create \n",
        "lists of 24 * 12 bins within the larger list of days).\n",
        "\n",
        "smoothingSize: the number of bins that we will be looking at to average (into \n",
        "one value).\n",
        "\"\"\"\n",
        "\n",
        "def CreateSubsetBins(binList, subSetSize):\n",
        "  \n",
        "  #Puts the 1-D binList into lists of intervals of hours, and adds those to a \n",
        "  #master binList\n",
        "  \n",
        "  if (subSetSize == \"days\"):\n",
        "    numHours = 24 * 12\n",
        "  #assuming months is 28 days\n",
        "  elif (subSetSize == \"months\"):\n",
        "    numHours = 24 * 12 * 28\n",
        "  else:\n",
        "    numHours = subSetSize * 12\n",
        "  \n",
        "  subSetBins = []\n",
        "\n",
        "  tempSubSet = []\n",
        "\n",
        "  for j in range(len(binList)):\n",
        "    if (j == 0):\n",
        "      tempSubSet.append(binList[j])\n",
        "      continue\n",
        "    if (j % numHours == numHours - 1): \n",
        "      tempSubSet.append(binList[j])\n",
        "      subSetBins.append(tempSubSet)\n",
        "      tempSubSet = []\n",
        "    else:\n",
        "      tempSubSet.append(binList[j])    \n",
        "  return subSetBins, numHours    \n",
        "      \n",
        "      \n",
        "def SubsetBins(binList, subSetSize, smoothingSize, averageMedian):      \n",
        "  \n",
        "  subSetBins, numHours = CreateSubsetBins(binList, subSetSize)\n",
        "  \n",
        "  #If there is a None, do not put it into the 3 month smoothing/averaging calculations \n",
        "  averageList = []\n",
        "  hourBinAmount = int(12 * smoothingSize)\n",
        "  cyclesInSubSet = int(numHours/hourBinAmount)\n",
        "  for i in range(len(subSetBins)):\n",
        "    singleIntervalList = []  \n",
        "    for j in range(cyclesInSubSet):\n",
        "      hourCycle = []\n",
        "      for k in range(hourBinAmount):\n",
        "        if (subSetBins[i][(hourBinAmount*j) + k] == None):\n",
        "          continue\n",
        "        hourCycle.append(subSetBins[i][(hourBinAmount*j) + k]) \n",
        "      averageHourCycle = 0\n",
        "      for s in range(len(hourCycle)):\n",
        "        averageHourCycle += hourCycle[s]\n",
        "      if not hourCycle:\n",
        "        averageHourCycle = 0\n",
        "      else:\n",
        "        if (averageMedian == 0):\n",
        "          averageHourCycle = averageHourCycle/len(hourCycle)\n",
        "        if (averageMedian == 1):  \n",
        "          averageHourCycle = statistics.median(hourCycle)\n",
        "      singleIntervalList.append(averageHourCycle)\n",
        "    averageList.append(singleIntervalList)\n",
        "\n",
        "  return averageList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnsHzjQIXkXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This function allows the user to control the specific formatting of the bins, \n",
        "and streamlines the returning of the different lists; it returns 6 different \n",
        "lists total:\n",
        "- the newly formatted glucose, basal, and bolus lists\n",
        "\"\"\"\n",
        "def executeFormatting(subsetSize, binSize):\n",
        "  allDaysGlucoseList = []\n",
        "  allDaysBasalList = []\n",
        "  allDaysBolusList = []\n",
        "  clusteringGlucose = []\n",
        "  clusteringBasal = []\n",
        "  clusteringBolus = []\n",
        "\n",
        "  for i in range(len(allPersonList)):\n",
        "    glucoseBin = ExpandBins(allPersonList[i][0][0])\n",
        "    #Note that smoothing size must be a factor of subSetSize\n",
        "    glucoseData = SubsetBins(glucoseBin, subsetSize, binSize, 0)\n",
        "    basalBin = ExpandBins(allPersonList[i][0][1])\n",
        "    #Note that smoothing size must be a factor of subSetSize\n",
        "    basalData = SubsetBins(basalBin, subsetSize, binSize, 0)\n",
        "    bolusBin = ExpandBins(allPersonList[i][0][2])\n",
        "    #Note that smoothing size must be a factor of subSetSize \n",
        "    bolusData = SubsetBins(bolusBin, subsetSize, binSize, 0)\n",
        "    for j in range(len(glucoseData)):\n",
        "      allDaysGlucoseList.append([glucoseData[j], allPersonList[i][1]])\n",
        "    for j in range(len(basalData)):  \n",
        "      allDaysBasalList.append([basalData[j], allPersonList[i][1]])\n",
        "    for j in range(len(bolusData)):  \n",
        "      allDaysBolusList.append([bolusData[j], allPersonList[i][1]])\n",
        "    # ONLY USE WHEN BINNING BY DAYS (this tells you if the day is a weekday or a weekend)\n",
        "    # This section is not needed as we eliminated the use of nones.\n",
        "    \"\"\"\n",
        "    for j in range(len(glucoseData)):\n",
        "      if (glucoseData[j] != None):\n",
        "        clusteringGlucose.append([glucoseData[j], allPersonList[i][1], allPersonList[i][0][0][288*j][3]])\n",
        "    for j in range(len(basalData)):\n",
        "      if (basalData[j] != None):\n",
        "        clusteringBasal.append([basalData[j], allPersonList[i][1], allPersonList[i][0][0][288*j][3]])  \n",
        "    for j in range(len(bolusData)):\n",
        "      if (bolusData[j] != None):\n",
        "        clusteringBolus.append([bolusData[j], allPersonList[i][1], allPersonList[i][0][0][288*j][3]]) \n",
        "    \"\"\"\n",
        "        \n",
        "  return allDaysGlucoseList, allDaysBasalList, allDaysBolusList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhHHTaq7_jpl",
        "colab_type": "text"
      },
      "source": [
        "#IN PROGRESS - testing named tuples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG2KOzug_i1P",
        "colab_type": "code",
        "outputId": "65b25dce-9c8b-4046-acb1-14b2ddcf90c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import collections\n",
        "\n",
        "Person = collections.namedtuple('Person', ['name', 'glucose', 'basal', 'bolus', 'dates'])\n",
        "\n",
        "sarah = Person(\"sarah\", [100, 110, 120], 0.5, 4, \"11/12\")\n",
        "sarah.glucose"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[100, 110, 120]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kws4Grz2TOlg",
        "colab_type": "text"
      },
      "source": [
        "#Kmeans Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nisjHcY2TLmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This set of operations allows for k-means of the data imported from above.  \n",
        "\n",
        "It can create a histogram that displays all the clusters worth of data.\n",
        "\n",
        "It also displays the \"knee\" of the curve, which in turn indicates the amount of\n",
        "clusters that we \"should\" take.\n",
        "\"\"\"\n",
        "\n",
        "def kMeansClustering(clusterAmount):\n",
        "  \n",
        "  #Elimination of \"None\" (empty) entries \n",
        "  allDaysGlucoseListToArray = []  \n",
        "  for i in range(len(allDaysGlucoseList)):\n",
        "    if allDaysGlucoseList[i][0] != None:\n",
        "      allDaysGlucoseListToArray.append([x for x in allDaysGlucoseList[i][0]])\n",
        "\n",
        "  \"\"\"\n",
        "  This block of (commented) code is a way of accounting for a particular \n",
        "  person's days tending to be low or high, and simply looking at how variable \n",
        "  a particular bin is in comparison to the extremes of the day.\n",
        "  \n",
        "  More specifically, we take the minimum of the particular time span (in most\n",
        "  cases one day), and the maximum, and then compute each entry = \n",
        "  (actual entry - minimum)/(maximum - minimum).\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  for i in range(len(allDaysGlucoseListToArray)):\n",
        "    maximum = 0\n",
        "    minimum = 100000000\n",
        "    for j in range(len(allDaysGlucoseListToArray[i])):\n",
        "      if allDaysGlucoseListToArray[i][j] > maximum:\n",
        "        maximum = allDaysGlucoseListToArray[i][j]\n",
        "      if allDaysGlucoseListToArray[i][j] < minimum:\n",
        "        minimum = allDaysGlucoseListToArray[i][j] \n",
        "    for j in range(len(allDaysGlucoseListToArray[i])):\n",
        "      allDaysGlucoseListToArray[i][j] = (allDaysGlucoseListToArray[i][j] - minimum)/(maximum - minimum)\n",
        "  \"\"\" \n",
        "  \n",
        "  #Creation of \"elbow\" of curve (for clusters)\n",
        "  X = np.array(allDaysGlucoseListToArray)\n",
        "  \n",
        "  distortions = []\n",
        "  K = range(1,10)\n",
        "  for k in K:\n",
        "    kmeanModel = KMeans(n_clusters=k).fit(X)\n",
        "    kmeanModel.fit(X)\n",
        "    distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
        "\n",
        "  # Plot the elbow\n",
        "  plt.plot(K, distortions, 'bx-')\n",
        "  plt.xlabel('k')\n",
        "  plt.ylabel('Distortion')\n",
        "  plt.title('The Elbow Method showing the optimal k')\n",
        "  plt.show()\n",
        "\n",
        "  #Addition and placement of the names of people with their days\n",
        "  n_clusters = clusterAmount\n",
        "  kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
        "  kmeans.labels_\n",
        "\n",
        "  glucoseToArrayCopyWithNames = []\n",
        "  for i in range(len(allDaysGlucoseList)):\n",
        "    tempList = []\n",
        "    tempVariable = \"\"\n",
        "    if allDaysGlucoseList[i][0] != None:\n",
        "      tempList.append(allDaysGlucoseList[i][0])\n",
        "      if \"111 Tidepool Files\" in allDaysGlucoseList[i][1]:\n",
        "        tempVariable = allDaysGlucoseList[i][1][66:-4]\n",
        "        tempVariable = tempVariable[:10]\n",
        "      else:\n",
        "        tempVariable = allDaysGlucoseList[i][1][58:-4]\n",
        "        tempVariable[:10]\n",
        "      tempList.append(tempVariable)\n",
        "      glucoseToArrayCopyWithNames.append(tempList)\n",
        "\n",
        "\n",
        "  #Attaching people's days to particular clusters, and thus days to clusters\n",
        "  listOfClusters = []\n",
        "  catch = 0\n",
        "  for i in range(n_clusters):\n",
        "    clusterDict = {}\n",
        "    for j in range(len(kmeans.labels_)):\n",
        "      if (kmeans.labels_[j] == i):\n",
        "        listOfKeys = clusterDict.keys()\n",
        "        check = False\n",
        "        for k in listOfKeys:\n",
        "          if (k == glucoseToArrayCopyWithNames[j][1]):\n",
        "            clusterDict[k] = clusterDict.get(k) + 1\n",
        "            check = True\n",
        "        if (check == False):    \n",
        "          clusterDict[glucoseToArrayCopyWithNames[j][1]] = 1\n",
        "    catch = catch + 1\n",
        "    listOfClusters.append(clusterDict)\n",
        "\n",
        "  #Plotting the histograms of each cluster's constituency\n",
        "  count = 0\n",
        "  for i in listOfClusters:\n",
        "    listOfKeys = i.keys()\n",
        "    listOfValues = []\n",
        "    for j in listOfKeys:\n",
        "      listOfValues.append(i.get(j))\n",
        "    tupleOfKeys = tuple(listOfKeys)\n",
        "    y_pos = np.arange(len(tupleOfKeys))\n",
        "    #plt.bar(y_pos, listOfValues, align='center', alpha=0.5)\n",
        "    plt.barh(y_pos, listOfValues)\n",
        "    plt.yticks(y_pos, tupleOfKeys, fontsize=5)\n",
        "    plt.xlabel('Bin Number per Day')\n",
        "    plt.ylabel('Blood Glucose Level (mg/dL)')\n",
        "    plt.title(count)\n",
        "    count = count + 1\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "  #Counting of the number of entries in each cluster.  \n",
        "  countList = []\n",
        "  for i in range(n_clusters):\n",
        "    countList.append(0)\n",
        "\n",
        "  for i in kmeans.labels_:\n",
        "    for j in range(n_clusters):\n",
        "      if (i == j):\n",
        "        countList[j] += 1\n",
        "        \n",
        "  #Plotting the clustes and printing the names\n",
        "  for i in range(n_clusters): \n",
        "    plt.plot.figsize=(15, 6)\n",
        "    plt.plot(kmeans.cluster_centers_[i])\n",
        "    print(i, \":\", countList[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEphSY6ymtdh",
        "colab_type": "text"
      },
      "source": [
        "# SARIMAX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YcFcXWvmr9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SARIMAX():  \n",
        "  plt.style.use('fivethirtyeight') \n",
        "  \n",
        "  weekGlucoseListL0 = allDaysGlucoseList[3][0][500:17500]  \n",
        "\n",
        "  weekBasalListL0 = allDaysBasalList[3][0][500:17500] \n",
        "  weekBasalListL30 = allDaysBasalList[3][0][499:17500] \n",
        "  weekBasalListL60 = allDaysBasalList[3][0][498:17500] \n",
        "  weekBasalListL90 = allDaysBasalList[3][0][497:17500]\n",
        "  weekBasalListL120 = allDaysBasalList[3][0][496:17500]\n",
        "  weekBasalListL150 = allDaysBasalList[3][0][495:17500]\n",
        "  weekBasalListL180 = allDaysBasalList[3][0][494:17500]\n",
        "\n",
        "  weekBolusListL0 = allDaysBolusList[3][0][500:17500]\n",
        "  weekBolusListL30 = allDaysBolusList[3][0][499:17500]\n",
        "  weekBolusListL60 = allDaysBolusList[3][0][498:17500]\n",
        "  weekBolusListL90 = allDaysBolusList[3][0][497:17500]\n",
        "  weekBolusListL120 = allDaysBolusList[3][0][496:17500]\n",
        "  weekBolusListL150 = allDaysBolusList[3][0][495:17500]\n",
        "  weekBolusListL180 = allDaysBolusList[3][0][494:17500]\n",
        "\n",
        "  totalInsulinListL0 = []\n",
        "  totalInsulinListL30 = []\n",
        "  totalInsulinListL60 = []\n",
        "  totalInsulinListL90 = []\n",
        "  totalInsulinListL120 = []\n",
        "  totalInsulinListL150 = []\n",
        "  totalInsulinListL180 = []\n",
        "  for i in range(len(weekGlucoseListL0)): \n",
        "    totalInsulinListL0.append(weekBasalListL0[i] + weekBolusListL0[i])\n",
        "    totalInsulinListL30.append(weekBasalListL30[i] + weekBolusListL30[i])\n",
        "    totalInsulinListL60.append(weekBasalListL60[i] + weekBolusListL60[i])\n",
        "    totalInsulinListL90.append(weekBasalListL90[i] + weekBolusListL90[i])\n",
        "    totalInsulinListL120.append(weekBasalListL120[i] + weekBolusListL120[i])\n",
        "    totalInsulinListL150.append(weekBasalListL150[i] + weekBolusListL150[i])\n",
        "    totalInsulinListL180.append(weekBasalListL180[i] + weekBolusListL180[i])\n",
        "\n",
        "  y = weekGlucoseListL0 \n",
        "  \n",
        "  '''\n",
        "  # Define the p, d and q parameters to take any value between 0 and 2\n",
        "  p = range(0, 3)\n",
        "  d = range(0, 2)\n",
        "  q = range(0, 1)\n",
        "\n",
        "  # Generate all different combinations of p, q and q triplets\n",
        "  pdq = list(itertools.product(p, d, q))\n",
        "\n",
        "  # Generate all different combinations of seasonal p, q and q triplets\n",
        "  seasonal_pdq = [(x[0], x[1], x[2], 24) for x in list(itertools.product(p, d, q))]\n",
        "\n",
        "  print('Examples of parameter combinations for Seasonal ARIMA...')\n",
        "  print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
        "  print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
        "  print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
        "  print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))\n",
        "\n",
        "  warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
        "  '''\n",
        "  \n",
        "  tmpList = [] \n",
        "  exogList = []\n",
        "  for i in range(len(weekGlucoseListL0)):\n",
        "    tmpList = [weekBolusListL0[i], weekBolusListL30[i], weekBolusListL60[i], weekBolusListL90[i], weekBolusListL120[i], weekBolusListL150[i], weekBolusListL180[i], weekBasalListL0[i], weekBasalListL30[i], weekBasalListL60[i], weekBasalListL90[i], weekBasalListL120[i], weekBasalListL150[i], weekBasalListL180[i]]\n",
        "    for j in range(len(tmpList)):\n",
        "      tmpList[j] = math.log((100 * tmpList[j]) + 10, 10) \n",
        "    exogList.append(tmpList)\n",
        "\n",
        "  exog = np.array(exogList) # greates array-type structure for exogenous variables \n",
        "  \n",
        "  '''\n",
        "  for param in pdq:\n",
        "      for param_seasonal in seasonal_pdq:\n",
        "          try:\n",
        "              mod = sm.tsa.statespace.SARIMAX(y,\n",
        "                                              order=param,\n",
        "                                              seasonal_order=param_seasonal)\n",
        "\n",
        "              results = mod.fit()\n",
        "\n",
        "              print('ARIMA{}x{}24 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
        "          except:\n",
        "            print(\"nope\")\n",
        "            continue\n",
        "  '''\n",
        "  \n",
        "  mod = sm.tsa.statespace.SARIMAX(y,\n",
        "                                  exog = exog,\n",
        "                                  order=(1, 0, 0),\n",
        "                                  seasonal_order=(1, 0, 0, 48))\n",
        "\n",
        "  results = mod.fit()\n",
        "\n",
        "  print(results.summary().tables[1])\n",
        "\n",
        "  results.plot_diagnostics(figsize=(15, 12))\n",
        "  plt.show()\n",
        "\n",
        "  pred = results.get_prediction(dynamic=False)\n",
        "  pred_ci = pred.conf_int()\n",
        "\n",
        "  plt.figure(figsize=(20, 10))\n",
        "  plt.plot(y, label='observed')\n",
        "  plt.plot(pred.predicted_mean, label='One-step ahead Forecast', alpha=.7)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  predicts = []\n",
        "  for i in pred.predicted_mean:\n",
        "    if (i < 0):\n",
        "      predicts.append(0)\n",
        "    else:  \n",
        "      predicts.append(i)\n",
        "\n",
        "  resids = [] \n",
        "  for i in range(1, len(y)):\n",
        "    resids.append(abs(y[i] - predicts[i]))\n",
        "\n",
        "  print(\"Our model's average residual\")  \n",
        "  print(statistics.mean(resids))\n",
        "\n",
        "  y1 = y[0:-1]  \n",
        "  y2 = y[1:]  \n",
        "  dummyResids = []\n",
        "  for i in range(len(y2)):\n",
        "    dummyResids.append(abs(y2[i] - y1[i]))\n",
        "\n",
        "  print(\"Dummy Guessing average residual\")  \n",
        "  print(statistics.mean(dummyResids)) \n",
        "\n",
        "\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  plt.plot(y[200:400])\n",
        "  plt.plot(predicts[200:400])\n",
        "  plt.plot(y[199:399])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  predicts = []\n",
        "  for i in pred.predicted_mean:\n",
        "    if (i < 0):\n",
        "      predicts.append(0)\n",
        "    else:  \n",
        "      predicts.append(i)\n",
        "\n",
        "  resids = [] \n",
        "  for i in range(1, len(y)):\n",
        "    if abs(y[i] - predicts[i]) < 100:\n",
        "      resids.append(y[i] - predicts[i])\n",
        "    else:  \n",
        "      resids.append(0)\n",
        "\n",
        "  r = resids\n",
        "\n",
        "  def smooth(r, box_pts):\n",
        "      box = np.ones(box_pts)/box_pts\n",
        "      r_smooth = np.convolve(r, box, mode='same')\n",
        "      return r_smooth\n",
        "\n",
        "  print(\"plotting the residuals to check for menstrual cycle\")\n",
        "  plt.figure(figsize=(20, 10))\n",
        "  plt.plot(smooth(r,100), 'r-', lw=2)  \n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yutGqrikm2Gw",
        "colab_type": "text"
      },
      "source": [
        "# Hierarchical Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daHzrruu0Yk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install dtw==1.3.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eo-HLTnnBgB",
        "colab_type": "code",
        "outputId": "f4366fb5-d641-4d11-b680-f647a29b40cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#DO NOT USE THIS ONE. for some reason, it changed in October and now outputs a different distance\n",
        "pip install dtw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dtw\n",
            "  Downloading https://files.pythonhosted.org/packages/66/a0/21d6ec377b8d5832218700e236205f8cdea38b3b2cdd0a732be170e2809b/dtw-1.4.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dtw) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from dtw) (1.2.0)\n",
            "Building wheels for collected packages: dtw\n",
            "  Building wheel for dtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dtw: filename=dtw-1.4.0-cp36-none-any.whl size=5316 sha256=b30cede1fdc8aa525cfcc32ed3965fdd60fe11d1d2bf4e75d2a135d88c24dfaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/8b/7a/947d67b53cd54948890a173527b0470ef56998812fc9d0a803\n",
            "Successfully built dtw\n",
            "Installing collected packages: dtw\n",
            "Successfully installed dtw-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZjVrUjSm-Qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fancy_dendrogram(*args, **kwargs):\n",
        "    max_d = kwargs.pop('max_d', None)\n",
        "    if max_d and 'color_threshold' not in kwargs:\n",
        "        kwargs['color_threshold'] = max_d\n",
        "    annotate_above = kwargs.pop('annotate_above', 0)\n",
        "\n",
        "    ddata = dendrogram(*args, **kwargs)\n",
        "\n",
        "    if not kwargs.get('no_plot', False):\n",
        "        plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
        "        plt.xlabel('sample index or (cluster size)')\n",
        "        plt.ylabel('distance')\n",
        "        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
        "            x = 0.5 * sum(i[1:3])\n",
        "            y = d[1]\n",
        "            if y > annotate_above:\n",
        "                plt.plot(x, y, 'o', c=c)\n",
        "                plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n",
        "                             textcoords='offset points',\n",
        "                             va='top', ha='center')\n",
        "        if max_d:\n",
        "            plt.axhline(y=max_d, c='k')\n",
        "    return ddata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pANR5_Iym6Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from dtw import dtw\n",
        "\n",
        "# We define two sequences x, y as numpy array\n",
        "# where y is actually a sub-sequence from x\n",
        "def DTW(X, Y):\n",
        "  x = np.array(X)\n",
        "  y = np.array(Y)\n",
        "\n",
        "  euclidean_norm = lambda x, y: np.abs(x - y)\n",
        "\n",
        "  d, cost_matrix, acc_cost_matrix, path = dtw(x, y, dist=euclidean_norm, w=8)\n",
        "\n",
        "  #Shows the distance matrix\n",
        "  '''\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  plt.imshow(acc_cost_matrix.T, origin='lower', cmap='gray', interpolation='nearest')\n",
        "  plt.plot(path[0], path[1], 'w')\n",
        "  plt.show()\n",
        "  '''\n",
        "  \n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFNf_APVm0nD",
        "colab_type": "code",
        "outputId": "b93d253b-4f66-4153-bda2-13d513be855c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "def HClustering():\n",
        "  \n",
        "  plt.style.use('default') \n",
        "\n",
        "  # a custom function that just computes Euclidean distance\n",
        "  clusteringGlucoseX = []\n",
        "  clusteringGlucose = allDaysGlucoseList[368:734]\n",
        "  for i in range(len(clusteringGlucose)):\n",
        "    clusteringGlucoseX.append(clusteringGlucose[i][0]) \n",
        "  DTW(clusteringGlucoseX[5], clusteringGlucoseX[10])\n",
        "  \n",
        "  clusteringBasalX = []\n",
        "  clusteringBasal = allDaysBasalList[368:734]\n",
        "  for i in range(len(clusteringBasal)):\n",
        "    clusteringBasalX.append(clusteringBasal[i][0]) \n",
        "  \n",
        "  clusteringBolusX = []\n",
        "  clusteringBolus = allDaysBolusList[368:734]\n",
        "  for i in range(len(clusteringBolus)):\n",
        "    clusteringBolusX.append(clusteringBolus[i][0])   \n",
        "\n",
        "  totalInsulinX = []\n",
        "  for i in range(len(clusteringBasalX)):\n",
        "    tmp = []\n",
        "    for j in range(len(clusteringBasalX[i])):\n",
        "      tmp.append(1000 * (clusteringBasalX[i][j] + clusteringBolusX[i][j]))\n",
        "    totalInsulinX.append(tmp)\n",
        "\n",
        "\n",
        "  # Optional way of only looking at trend \n",
        "  '''\n",
        "  for i in range(len(clusteringGlucoseX)):\n",
        "    minimum = min(clusteringGlucoseX[i])\n",
        "    maximum = max(clusteringGlucoseX[i])\n",
        "    for j in range(len(clusteringGlucoseX[i])):\n",
        "      clusteringGlucoseX[i][j] = (clusteringGlucoseX[i][j] - minimum)/(maximum-minimum)  \n",
        "  '''  \n",
        "\n",
        "  X = clusteringGlucoseX\n",
        "\n",
        "  # Make the Clusters\n",
        "  #Z = hac.linkage(X, method='average', metric='euclidean')\n",
        "  Z = hac.linkage(X, method = 'average', metric=DTW)\n",
        "\n",
        "\n",
        "  # Dendrogram with more information (Key part is max_d)\n",
        "  plt.figure(figsize=(15, 10))\n",
        "  fancy_dendrogram(\n",
        "      Z,\n",
        "      leaf_rotation=90.,\n",
        "      max_d=27,\n",
        "      annotate_above=15,\n",
        "  )\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  max_d = 27\n",
        "  clusters = fcluster(Z, max_d, criterion='distance')\n",
        "\n",
        "  # changes the cluster list so it will only reflect clusters with more than 6 elements (everything else gets set to cluster 0 for \"outlier\")\n",
        "  countList = []\n",
        "  editedClusters = []\n",
        "  for i in range(100):\n",
        "    count = 0\n",
        "    for j in range(len(clusters)):\n",
        "      if (clusters[j] == i):\n",
        "        count += 1\n",
        "    countList.append(count) \n",
        "  for i in range(len(clusters)):\n",
        "    if (countList[clusters[i]] > 6):\n",
        "      editedClusters.append(clusters[i])\n",
        "    else:\n",
        "      editedClusters.append(0)\n",
        "\n",
        "  # puts a list of each series into the cluster dictionary according to which cluster it is in  \n",
        "  clusterDict = {}\n",
        "  indexCount = 0\n",
        "  for i in range(len(editedClusters)):\n",
        "    tmpList = []\n",
        "    if (editedClusters[i] not in clusterDict):\n",
        "      clusterDict[editedClusters[i]] = [] \n",
        "    tmpList = clusterDict[editedClusters[i]]  \n",
        "    tmpList.append(X[indexCount])\n",
        "    clusterDict[editedClusters[i]] = tmpList\n",
        "    indexCount += 1 \n",
        "\n",
        "  clusterDictInsulin = {}\n",
        "  indexCount = 0\n",
        "  for i in range(len(editedClusters)):\n",
        "    tmpList = []\n",
        "    if (editedClusters[i] not in clusterDictInsulin):\n",
        "      clusterDictInsulin[editedClusters[i]] = [] \n",
        "    tmpList = clusterDictInsulin[editedClusters[i]]  \n",
        "    tmpList.append(totalInsulinX[indexCount])\n",
        "    clusterDictInsulin[editedClusters[i]] = tmpList\n",
        "    indexCount += 1 \n",
        "\n",
        "  # Creates a dictionary of next cluster percentages (prediction accuracy)    \n",
        "  keys = list(clusterDict.keys())     \n",
        "  listOfClusters = list(editedClusters)    \n",
        "  nextPrediction = {}\n",
        "  for i in keys:\n",
        "    predictions = {}\n",
        "    count = 0\n",
        "    for j in range(len(listOfClusters) - 1):\n",
        "      if (listOfClusters[j] == i):\n",
        "        count += 1\n",
        "        if (listOfClusters[j + 1] not in predictions):\n",
        "          predictions[listOfClusters[j + 1]] = 1\n",
        "        else:\n",
        "          predictions[listOfClusters[j + 1]] = predictions[listOfClusters[j + 1]] + 1\n",
        "    for k in predictions:\n",
        "      predictions[k] = int(100 * predictions[k]/count)\n",
        "    nextPrediction[i] = predictions  \n",
        "\n",
        "\n",
        "  # Averages all the points in a cluster to create and print a centroid for each cluster\n",
        "  centroidDict = clusterDict.copy()\n",
        "  for i in centroidDict:\n",
        "    centroid = []\n",
        "    count = 0\n",
        "    for j in range(len(centroidDict[i][0])):\n",
        "      for k in range(len(centroidDict[i])):\n",
        "        count += centroidDict[i][k][j]\n",
        "      centroid.append(count/len(centroidDict[i]))  \n",
        "      count = 0 \n",
        "    centroidDict[i] = centroid  \n",
        "\n",
        "  centroidDictInsulin = clusterDictInsulin.copy()\n",
        "  for i in centroidDictInsulin:\n",
        "    centroid = []\n",
        "    count = 0\n",
        "    for j in range(len(centroidDictInsulin[i][0])):\n",
        "      for k in range(len(centroidDictInsulin[i])):\n",
        "        count += centroidDictInsulin[i][k][j]\n",
        "      centroid.append(count/len(centroidDictInsulin[i]))  \n",
        "      count = 0 \n",
        "    centroidDictInsulin[i] = centroid   \n",
        "\n",
        "  for i in centroidDict:\n",
        "    plt.plot(centroidDict[i])\n",
        "    plt.plot(centroidDictInsulin[i])\n",
        "    print(i)\n",
        "    print(len(clusterDict[i]))\n",
        "    plt.show()   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.177128314088534"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2-AncTnrJ_5",
        "colab_type": "text"
      },
      "source": [
        "# Main()\n",
        "\n",
        "This block of raw code contains all the actual execution of code.  By running the whole block, you will execute all the functions contained within this document on the data, and the output will appear below.  \n",
        "\n",
        "The process of loading the data into bins for all the data can take a signficant amount of time, though; approximately 20 minutes.  The kmeans clustering can also take about 5 minutes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PtjXVuaEQM5",
        "colab_type": "text"
      },
      "source": [
        "#THINGS TO LOOK BACK AT\n",
        "Look at the \"smoothing\" of basal and bolus values in the bin formatting functions\n",
        "\n",
        "Make sure time zones are correct \n",
        "\n",
        "(done) ADD TIMES TO KEEP THROUGH TO GRAPHING!!!\n",
        "\n",
        "make bins in the \"right\" order\n",
        "\n",
        "only take most common cluster into account for this next test???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUWMJ7xEToPm",
        "colab_type": "code",
        "outputId": "fb1e6305-83a4-4f4c-ec26-cdd538eaa121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "\"\"\"\n",
        "We now import the file names from a csv file, and create a 4 dimensional list\n",
        "called personBinList that contains each person, and within each person, their \n",
        "glucose, basal, and bolus, and within each of those, their respective bins.\n",
        "\n",
        "WARNING: The importation of all the data files (5 original + 66 new) takes a \n",
        "relatively long time (about 20 minutes).\n",
        "\"\"\"\n",
        "\n",
        "old, new = ImportFileNames(\"drive/Shared drives/Diabetes Data Science 2019/fileNames.csv\")\n",
        "allPersonList = []\n",
        "for i in old:\n",
        "  cgm, bas, bol, start, end = ImportData(i, \"old\")\n",
        "  print(i)\n",
        "  personBinList = []\n",
        "  personBinList.append(CreateGlucoseBins(cgm, \"old\", start, end))\n",
        "  personBinList.append(CreateBasalBins(bas, \"old\", start, end))\n",
        "  personBinList.append(CreateBolusBins(bol, \"old\", start, end))\n",
        "  allPersonList.append([personBinList, i])\n",
        "for i in new: \n",
        "  cgm, bas, bol, start, end = ImportData(i, \"new\")\n",
        "  print(i)\n",
        "  personBinList = []\n",
        "  personBinList.append(CreateGlucoseBins(cgm, \"new\", start, end))\n",
        "  personBinList.append(CreateBasalBins(bas, \"new\", start, end))\n",
        "  personBinList.append(CreateBolusBins(bol, \"new\", start, end))\n",
        "  allPersonList.append([personBinList, i])\n",
        "\n",
        "\n",
        "allDaysGlucoseList, allDaysBasalList, allDaysBolusList = executeFormatting(\"days\", 1/12)    \n",
        "#Kmeans clustering function call\n",
        "kMeansClustering(8)\n",
        "    \n",
        "allDaysGlucoseList, allDaysBasalList, allDaysBolusList = executeFormatting(8760, 0.5)       \n",
        "SARIMAX()    \n",
        "    \n",
        "allDaysGlucoseList, allDaysBasalList, allDaysBolusList = executeFormatting(\"days\", 3/12)  \n",
        "HClustering()  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,16,18,19,21,22,23,24,25,26,27,28,29,30,31,32,33,35,36,37,39,43,45,47,48,50,51,52,56,57,59,60,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "drive/Shared drives/Diabetes Data Science 2019/data files/Brandon_data.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (19,20,21,22,23,24,26,27,28,29,30,31,32,33,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "drive/Shared drives/Diabetes Data Science 2019/Winter 2020 Tidepool data/Johanna 1.25.20 Tidepool data.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,14,16,17,18,20,21,22,23,25,26,27,28,29,30,31,32,34,35,36,37,38,40,41,42,45,47,48,49,51,53,54,56,57,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "drive/Shared drives/Diabetes Data Science 2019/data files/Jason_data.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (1,2,3,4,5,7,9,10,11,12,14,15,16,17,19,21,23,24,25,27,28,34,35,39,40,43,46,48,49,51,52,53,57,58,60,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "drive/Shared drives/Diabetes Data Science 2019/data files/Paul_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}